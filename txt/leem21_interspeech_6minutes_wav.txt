 Hello everyone my name is Hongin-Linn and today I will introduce our research that focuses on how to deal with the noisy speech for speech emotion recognition in real world environment. So why we do this work? Detecting an emotion from a recorded speech is a useful technology that can be applied to various services like entertainment. Oh, excuse me. Is the raise of point working? Oh, okay. like entertainment or daily health care system. Such useful services can be provided to the human's daily lives by deploying the SEO system on devices like smartphone or smart speakers. However, when deploying the SEL system on real world applications, we have to consider that there are many types of complex background noise in real world environment. People use their devices in various places and in the real world conditions, those environments are highly likely to contain complex types of background noise. Such background noise can degrade the quality of speed signal reading to the SCA system to be hard to detect the emotional information from the recorded speech. So improving the noise robustness for speech emotion recognition is really important to increase the applicability of speech emotional recognition system. What we try to do is to borrow the semi-supervised learning framework to solve this issue. In this framework, the system continuously record the noise speed samples from the noisy target environment. With this collected noise speed samples, we can simultaneously train this SEM model with the noise speed samples from the target environment and the large amount of clean speed samples from the public coppers. We have focused on the emotional attribute which gives us a fine granularity of emotion. We focus on predicting the scores of arousal, balance, and dominance prediction. In this framework we have to consider that such collected noise samples are not likely to contain their emotional label. Entering the emotional labels for all of them takes too much time to collect a large amount of collective noise speed samples. So we have to investigate the approach that can exploit the noise speed samples without requiring their labeling process. What I want to highlight for this approach is a ladder network-based solution. Leadon network uses a denoising auto-encorder architecture consisting of encoder, decoder, and the lateral connection between them. This model can utilize a unlabeled data set during training reading to the model to decrease the domain mismatch between the training set and test set. How can they do that? So the model is simultaneously trained to two different tasks. The first task is prediction task. In this task, the encoder predicts the emotional label of the label data set. To regularize the prediction, they add the arbitrary Gaussian noise for each hidden layer. The second task is a reconstruction task. In the reconstruction task, decoder reconstruct the clean representation from the noisy noisy encoder. To reconstruct the clean representation, they use a retro connection from the noisy encoder and the denoiser in their each layer. So by simultaneously training the model with the prediction and reconstruction task, this model can predict the emotion label as well as containing the information of unlabeled data set. However, in case of applying that the network-based solution to our formulation, we have to consider that there is a background noise in our unlabeled data set. Such background noise should be included in the highest layer of encoder to reconstruct the original speech. Such noisy information can disrupt the emotional prediction so we explore the idea to separate the noisy information from the prediction test. Therefore, we propose the decouple network architecture which decouples the last hidden layer of encoder into two different embeddings. First embedding is reconstruction embedding. Reconstructing is only fed into the decoder and decoder does not construct the emotional related layers. So this scheme allows the reconstruction embedding to contain the information needed for a reconstruction task regardless of the emotional information. The other embedding is emotion embedding. This embedding is only connected to the output layer and this embedding is not included in the reconstruction task. So this scheme allows the emotion embedding to exclusively contain the emotional information. The last of the lower rails are jointly trained with the prediction LA construction test, which is same as the traditional ladder network training. So by using this scheme, we can separate the noisy information from the prediction task as well as keeping the original objective of traditional ladder network training. This model is trained to minimize the summation of prediction and reconstruction laws. To predict the emotional attribute score, we use concurrence correlation coefficient, which is generally called as CCC. In this model, we calculate the agreement between the predictor label and the emotional label. So by using the 1-9cCC as a prediction loss,